{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMF6bNligvXQDiJrDkK0im1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maxxx-VS/CV-Arduino/blob/main/Yolo_mobil_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python opencv-python-headless tflite-runtime numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUcKqwcMvF7a",
        "outputId": "2c66b6d9-1fc9-4c19-8732-09f19defd9a7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Collecting tflite-runtime\n",
            "  Downloading tflite_runtime-2.14.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Downloading tflite_runtime-2.14.0-cp311-cp311-manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tflite-runtime\n",
            "Successfully installed tflite-runtime-2.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Импорт библиотек\n",
        "import cv2\n",
        "import time\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "import tflite_runtime.interpreter as tflite\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "# Скачивание модели YOLOv4-tiny в формате Darknet\n",
        "def download_file(url, filename):\n",
        "    print(f\"Downloading {filename} from {url}...\")\n",
        "    urllib.request.urlretrieve(url, filename)\n",
        "    print(f\"{filename} saved.\")\n",
        "\n",
        "# Скачиваем веса и конфигурацию модели\n",
        "weights_url = \"https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.weights\"\n",
        "cfg_url = \"https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4-tiny.cfg\"\n",
        "download_file(weights_url, \"yolov4-tiny.weights\")\n",
        "download_file(cfg_url, \"yolov4-tiny.cfg\")\n",
        "\n",
        "# Установка инструмента для конвертации Darknet в TFLite\n",
        "!git clone https://github.com/hunglc007/tensorflow-yolov4-tflite.git\n",
        "%cd tensorflow-yolov4-tflite\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# Конвертация модели в TensorFlow Lite\n",
        "!python save_model.py --weights ../yolov4-tiny.weights --output ./checkpoints/yolov4-tiny --input_size 416 --model yolov4 --framework tflite\n",
        "\n",
        "# Конвертация SavedModel в TFLite\n",
        "import tensorflow as tf\n",
        "\n",
        "saved_model_dir = './checkpoints/yolov4-tiny'\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Сохранение TFLite модели\n",
        "with open('yolov4-tiny.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "# Загрузка модели YOLOv4-tiny\n",
        "interpreter = tflite.Interpreter(model_path='yolov4-tiny.tflite')\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Получение информации о входных и выходных тензорах\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Параметры модели\n",
        "input_shape = input_details[0]['shape']\n",
        "input_width, input_height = input_shape[1], input_shape[2]\n",
        "\n",
        "# Функция для захвата видеопотока с камеры в Colab\n",
        "def capture_camera():\n",
        "    js = Javascript('''\n",
        "        async function capture() {\n",
        "            const video = document.createElement('video');\n",
        "            video.style.display = 'none';\n",
        "            document.body.appendChild(video);\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "            const canvas = document.createElement('canvas');\n",
        "            canvas.width = video.videoWidth;\n",
        "            canvas.height = video.videoHeight;\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "            stream.getVideoTracks()[0].stop();\n",
        "            document.body.removeChild(video);\n",
        "            return canvas.toDataURL('image/jpeg', 0.8);\n",
        "        }\n",
        "    ''')\n",
        "    display(js)\n",
        "    data = eval_js('capture()')\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "    return binary\n",
        "\n",
        "# Переменные для расчета FPS\n",
        "frame_count = 0\n",
        "start_time = time.time()\n",
        "\n",
        "while True:\n",
        "    # Захват кадра с камеры\n",
        "    frame_data = capture_camera()\n",
        "    frame = cv2.imdecode(np.frombuffer(frame_data, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
        "\n",
        "    # Преобразование кадра для модели\n",
        "    resized_frame = cv2.resize(frame, (input_width, input_height))\n",
        "    input_data = np.expand_dims(resized_frame, axis=0)\n",
        "    input_data = (input_data / 255.0).astype(np.float32)\n",
        "\n",
        "    # Запуск инференса\n",
        "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Получение результатов\n",
        "    boxes = interpreter.get_tensor(output_details[0]['index'])\n",
        "    scores = interpreter.get_tensor(output_details[1]['index'])\n",
        "    classes = interpreter.get_tensor(output_details[2]['index'])\n",
        "\n",
        "    # Отображение результатов в консоль\n",
        "    for i in range(len(scores[0])):\n",
        "        if scores[0][i] > 0.5:  # Фильтр по confidence score\n",
        "            class_id = int(classes[0][i])\n",
        "            confidence = scores[0][i]\n",
        "            box = boxes[0][i]\n",
        "            print(f\"Class: {class_id}, Confidence: {confidence:.2f}, Box: {box}\")\n",
        "\n",
        "    # Расчет и вывод FPS\n",
        "    frame_count += 1\n",
        "    if frame_count % 10 == 0:\n",
        "        end_time = time.time()\n",
        "        fps = frame_count / (end_time - start_time)\n",
        "        print(f\"FPS: {fps:.2f}\")\n",
        "        frame_count = 0\n",
        "        start_time = time.time()\n",
        "\n",
        "    # Отображение кадра с bounding boxes (опционально)\n",
        "    cv2.imshow('YOLOv4-tiny Detection', frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Освобождение ресурсов\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s0W_soLEwfe4",
        "outputId": "6e7d5815-1d10-4eb0-fd25-f7d54815a622"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading yolov4-tiny.weights from https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.weights...\n",
            "yolov4-tiny.weights saved.\n",
            "Downloading yolov4-tiny.cfg from https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4-tiny.cfg...\n",
            "yolov4-tiny.cfg saved.\n",
            "Cloning into 'tensorflow-yolov4-tflite'...\n",
            "remote: Enumerating objects: 790, done.\u001b[K\n",
            "remote: Total 790 (delta 0), reused 0 (delta 0), pack-reused 790 (from 1)\u001b[K\n",
            "Receiving objects: 100% (790/790), 197.64 MiB | 17.60 MiB/s, done.\n",
            "Resolving deltas: 100% (374/374), done.\n",
            "/content/tensorflow-yolov4-tflite\n",
            "\u001b[31mERROR: Ignored the following yanked versions: 3.4.11.39, 3.4.17.61, 4.4.0.42, 4.4.0.44, 4.5.4.58, 4.5.5.62, 4.7.0.68\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement opencv-python==4.1.1.26 (from versions: 3.4.0.14, 3.4.10.37, 3.4.11.41, 3.4.11.43, 3.4.11.45, 3.4.13.47, 3.4.15.55, 3.4.16.57, 3.4.16.59, 3.4.17.63, 3.4.18.65, 4.3.0.38, 4.4.0.40, 4.4.0.46, 4.5.1.48, 4.5.3.56, 4.5.4.60, 4.5.5.64, 4.6.0.66, 4.7.0.72, 4.8.0.74, 4.8.0.76, 4.8.1.78, 4.9.0.80, 4.10.0.82, 4.10.0.84, 4.11.0.86)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for opencv-python==4.1.1.26\u001b[0m\u001b[31m\n",
            "\u001b[0m2025-03-10 16:01:48.302684: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741622508.335260    4458 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741622508.345400    4458 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-10 16:01:48.375703: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-03-10 16:01:53.554291: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1741622513.557391    4458 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/tensorflow-yolov4-tflite/save_model.py\", line 58, in <module>\n",
            "    app.run(main)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/absl/app.py\", line 308, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/absl/app.py\", line 254, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "             ^^^^^^^^^^\n",
            "  File \"/content/tensorflow-yolov4-tflite/save_model.py\", line 54, in main\n",
            "    save_tf()\n",
            "  File \"/content/tensorflow-yolov4-tflite/save_model.py\", line 20, in save_tf\n",
            "    feature_maps = YOLO(input_layer, NUM_CLASS, FLAGS.model, FLAGS.tiny)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/tensorflow-yolov4-tflite/core/yolov4.py\", line 25, in YOLO\n",
            "    return YOLOv4(input_layer, NUM_CLASS)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/tensorflow-yolov4-tflite/core/yolov4.py\", line 72, in YOLOv4\n",
            "    route_1, route_2, conv = backbone.cspdarknet53(input_layer)\n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/tensorflow-yolov4-tflite/core/backbone.py\", line 41, in cspdarknet53\n",
            "    input_data = common.convolutional(input_data, (3, 3,  3,  32), activate_type=\"mish\")\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/tensorflow-yolov4-tflite/core/common.py\", line 38, in convolutional\n",
            "    conv = mish(conv)\n",
            "           ^^^^^^^^^^\n",
            "  File \"/content/tensorflow-yolov4-tflite/core/common.py\", line 42, in mish\n",
            "    return x * tf.math.tanh(tf.math.softplus(x))\n",
            "                            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\", line 88, in wrapper\n",
            "    return op(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/common/keras_tensor.py\", line 138, in __tf_tensor__\n",
            "    raise ValueError(\n",
            "ValueError: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n",
            "\n",
            "```\n",
            "x = Input(...)\n",
            "...\n",
            "tf_fn(x)  # Invalid.\n",
            "```\n",
            "\n",
            "What you should do instead is wrap `tf_fn` in a layer:\n",
            "\n",
            "```\n",
            "class MyLayer(Layer):\n",
            "    def call(self, x):\n",
            "        return tf_fn(x)\n",
            "\n",
            "x = MyLayer()(x)\n",
            "```\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "SavedModel file does not exist at: ./checkpoints/yolov4-tiny/{saved_model.pbtxt|saved_model.pb}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-79cf7a5fd4dd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0msaved_model_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./checkpoints/yolov4-tiny'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_model_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mfrom_saved_model\u001b[0;34m(cls, saved_model_dir, signature_keys, tags)\u001b[0m\n\u001b[1;32m   2240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2241\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2242\u001b[0;31m       \u001b[0msaved_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_model_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2243\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignature_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m       \u001b[0msignature_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(export_dir, tags, options)\u001b[0m\n\u001b[1;32m    910\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m     \u001b[0mexport_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_partial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"root\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_partial\u001b[0;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m   saved_model_proto, debug_info = (\n\u001b[0;32m-> 1016\u001b[0;31m       loader_impl.parse_saved_model_with_debug_info(export_dir))\n\u001b[0m\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m   \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model_with_debug_info\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mMissing\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0minfo\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mfine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m   \"\"\"\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0msaved_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m   debug_info_path = file_io.join(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    117\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Cannot parse file {path_to_pbtxt}: {str(e)}.\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     raise IOError(\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;34mf\"SavedModel file does not exist at: {export_dir}{os.path.sep}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;34mf\"{{{constants.SAVED_MODEL_FILENAME_PBTXT}|\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: ./checkpoints/yolov4-tiny/{saved_model.pbtxt|saved_model.pb}"
          ]
        }
      ]
    }
  ]
}